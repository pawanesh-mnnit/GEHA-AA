{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3695e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfa9e81",
   "metadata": {},
   "source": [
    "### User Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b6adb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_EXTRACT = False \n",
    "SAMPLE_RATE = 1  \n",
    "FEAT_DIM = 512\n",
    "W_RGB = 0.6\n",
    "W_FLOW = 0.4\n",
    "K = 5             \n",
    "DROP = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54896b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_CSV   = Path(r\"EPIC-Kitchens\\Labels\\P01_05.csv\")\n",
    "OUTPUT_FUSED_CSV = Path(r\"EPIC-Kitchens\\Features\\FusedFeatures\\P01_05_fused_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdf4834",
   "metadata": {},
   "source": [
    "### Loss mode (choose one): \n",
    "_\"ce\",\"focal\",\"smooth\",\"contrast\",\"graph\",\"combined\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66cc6a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e958f231f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss mode (choose one): \"ce\",\"focal\",\"smooth\",\"contrast\",\"graph\",\"combined\"\n",
    "LOSS_MODE = \"combined\"\n",
    "\n",
    "# Device\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Outputs\n",
    "OUTPUT_FUSED_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "BEST_MODEL_PATH = Path(r\"./Model/P01_05_best_model.pth\")\n",
    "\n",
    "# Repro\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f2b0a9",
   "metadata": {},
   "source": [
    "### LOAD FUSED CSV & LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61b19211",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_fused_csv_by_path(fused_csv_path: str):\n",
    "    fp = Path(fused_csv_path)\n",
    "    if not fp.exists():\n",
    "        raise FileNotFoundError(f\"Fused features CSV not found: {fp}\")\n",
    "    df = pd.read_csv(fp)\n",
    "    if \"frame_idx\" not in df.columns:\n",
    "        raise KeyError(\"Fused CSV must contain 'frame_idx' column\")\n",
    "    df[\"frame_idx\"] = df[\"frame_idx\"].astype(int)\n",
    "    df = df.sort_values(\"frame_idx\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def load_label_csv_by_path(label_csv_path: str):\n",
    "    fp = Path(label_csv_path)\n",
    "    if not fp.exists():\n",
    "        raise FileNotFoundError(f\"Label CSV not found: {fp}\")\n",
    "    df = pd.read_csv(fp)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c49d75",
   "metadata": {},
   "source": [
    "### DATASET Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "272bb9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IGNORE_INDEX = -1\n",
    "\n",
    "class SingleVideoAnticipationDataset(Dataset):\n",
    "    def __init__(self\n",
    "                 , fused_df_or_path, labels_df_or_path,\n",
    "                 t_obs: int, k_fut: int, feat_dim: int,\n",
    "                 fps: float, horizons_s):\n",
    "        # load\n",
    "        if isinstance(fused_df_or_path, (str, Path)):\n",
    "            fused_df = pd.read_csv(fused_df_or_path)\n",
    "        else:\n",
    "            fused_df = fused_df_or_path.copy()\n",
    "        if isinstance(labels_df_or_path, (str, Path)):\n",
    "            labels_df = pd.read_csv(labels_df_or_path)\n",
    "        else:\n",
    "            labels_df = labels_df_or_path.copy()\n",
    "\n",
    "        if \"frame_idx\" not in fused_df.columns:\n",
    "            raise KeyError(\"fused_df must contain 'frame_idx'\")\n",
    "        fused_df[\"frame_idx\"] = fused_df[\"frame_idx\"].astype(int)\n",
    "        self.fused_df = fused_df.set_index(\"frame_idx\", drop=False).sort_index()\n",
    "        self.labels_df = labels_df.reset_index(drop=True)\n",
    "\n",
    "        if not all(c in self.labels_df.columns for c in [\"StartFrame\", \"EndFrame\"]):\n",
    "            raise KeyError(\"labels_df must contain StartFrame and EndFrame\")\n",
    "\n",
    "        self.t_obs = int(t_obs)\n",
    "        self.k_fut = int(k_fut)\n",
    "        self.feat_dim = int(feat_dim)\n",
    "        self.feat_cols = [f\"feat_{i}\" for i in range(self.feat_dim)]\n",
    "        self.fps = float(fps)\n",
    "        assert len(horizons_s) == self.k_fut, \"len(horizons_s) must equal k_fut\"\n",
    "        self.horizons_s = list(horizons_s)\n",
    "\n",
    "        # build samples: one per label row (use EndFrame as obs_end)\n",
    "        self.samples = []\n",
    "        for ridx, row in self.labels_df.iterrows():\n",
    "            try:\n",
    "                obs_end = int(row[\"EndFrame\"])\n",
    "            except:\n",
    "                continue\n",
    "            self.samples.append({\"label_row_idx\": int(ridx), \"obs_end\": obs_end})\n",
    "\n",
    "        if len(self.samples) == 0:\n",
    "            raise RuntimeError(\"No valid label rows found\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def _time_based_future_labels(self, obs_end: int):\n",
    "        labels_df = self.labels_df\n",
    "        def pick(cols):\n",
    "            for c in cols:\n",
    "                if c in labels_df.columns:\n",
    "                    return c\n",
    "            return None\n",
    "        vcol = pick([\"Verb_class\",\"verb\",\"Verb\",\"verb_class\"])\n",
    "        ncol = pick([\"Noun_class\",\"noun\",\"Noun\",\"noun_class\"])\n",
    "        acol = pick([\"Action_class\",\"action\",\"Action\",\"ActionLabel\"])\n",
    "        verb_targets   = []\n",
    "        noun_targets   = []\n",
    "        action_targets = []\n",
    "        for h_sec in self.horizons_s:\n",
    "            future_frame = obs_end + int(round(h_sec * self.fps))\n",
    "            seg = labels_df[(labels_df[\"StartFrame\"] <= future_frame) &\n",
    "                            (labels_df[\"EndFrame\"]   >= future_frame)]\n",
    "            if seg.empty:\n",
    "                verb_targets.append(IGNORE_INDEX)\n",
    "                noun_targets.append(IGNORE_INDEX)\n",
    "                action_targets.append(IGNORE_INDEX)\n",
    "            else:\n",
    "                row = seg.iloc[0]\n",
    "                if vcol is not None and not pd.isna(row[vcol]):\n",
    "                    verb_targets.append(int(row[vcol]))\n",
    "                else:\n",
    "                    verb_targets.append(IGNORE_INDEX)\n",
    "                if ncol is not None and not pd.isna(row[ncol]):\n",
    "                    noun_targets.append(int(row[ncol]))\n",
    "                else:\n",
    "                    noun_targets.append(IGNORE_INDEX)\n",
    "                if acol is not None and not pd.isna(row[acol]):\n",
    "                    action_targets.append(int(row[acol]))\n",
    "                else:\n",
    "                    action_targets.append(IGNORE_INDEX)\n",
    "        return {\n",
    "            \"verb\":   torch.LongTensor(verb_targets),\n",
    "            \"noun\":   torch.LongTensor(noun_targets),\n",
    "            \"action\": torch.LongTensor(action_targets)\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rec = self.samples[idx]\n",
    "        obs_end = rec[\"obs_end\"]\n",
    "        obs_start = obs_end - (self.t_obs - 1)\n",
    "        if obs_start < 0:\n",
    "            obs_start = 0\n",
    "            obs_end = obs_start + (self.t_obs - 1)\n",
    "\n",
    "        fused_idx_min = int(self.fused_df.index.min())\n",
    "        fused_idx_max = int(self.fused_df.index.max())\n",
    "        obs_end = min(obs_end, fused_idx_max)\n",
    "        obs_start = max(obs_end - (self.t_obs - 1), fused_idx_min)\n",
    "\n",
    "        desired = list(range(obs_start, obs_end + 1))\n",
    "        sel = self.fused_df.reindex(desired).fillna(method=\"ffill\").fillna(method=\"bfill\").fillna(0.0)\n",
    "\n",
    "        if sel.shape[0] < self.t_obs:\n",
    "            if sel.shape[0] == 0:\n",
    "                zero_row = {c:0.0 for c in self.feat_cols}\n",
    "                sel = pd.DataFrame([zero_row] * self.t_obs)\n",
    "            else:\n",
    "                first = sel.iloc[[0]]\n",
    "                pads = pd.concat([first] * (self.t_obs - sel.shape[0]), ignore_index=True)\n",
    "                sel = pd.concat([pads, sel.reset_index(drop=True)], ignore_index=True)\n",
    "\n",
    "        for c in self.feat_cols:\n",
    "            if c not in sel.columns:\n",
    "                sel[c] = 0.0\n",
    "\n",
    "        F_window = torch.from_numpy(sel[self.feat_cols].values).float()   # (T_obs, FEAT_DIM)\n",
    "        y_multi = self._time_based_future_labels(obs_end)\n",
    "        meta = {\"obs_start\": int(obs_start),\n",
    "                \"obs_end\":   int(obs_end),\n",
    "                \"label_row_idx\": int(rec[\"label_row_idx\"])}\n",
    "        return F_window, y_multi, meta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203cd1ce",
   "metadata": {},
   "source": [
    "### GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02fbadd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_topk_edge_index(features: torch.Tensor, k=K, device=None):\n",
    "    \"\"\"\n",
    "    Compute top-k edges on the device of `features`.\n",
    "    - features: (T, D) float tensor (can be on CPU or GPU)\n",
    "    - returns: edge_index (2, E) long tensor on same device as features (or 'device' arg)\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = features.device\n",
    "    features = features.to(device)\n",
    "    Tn = int(features.size(0))\n",
    "    if Tn == 0:\n",
    "        return torch.zeros((2, 0), dtype=torch.long, device=device)\n",
    "    x = F.normalize(features, dim=1)          # (T, D)\n",
    "    sim = torch.matmul(x, x.t())              # (T, T)\n",
    "    sim.fill_diagonal_(-1.0)\n",
    "    kk = min(max(0, int(k)), max(0, Tn - 1))\n",
    "    if kk <= 0:\n",
    "        return torch.zeros((2, 0), dtype=torch.long, device=device)\n",
    "    vals, idxs = torch.topk(sim, kk, dim=1)   # (T, kk)\n",
    "    src = torch.arange(Tn, device=device).unsqueeze(1).expand(-1, kk).reshape(-1)\n",
    "    dst = idxs.reshape(-1)\n",
    "    edge = torch.stack([src, dst], dim=0)\n",
    "    edge_rev = torch.stack([dst, src], dim=0)\n",
    "    return torch.cat([edge, edge_rev], dim=1).long()\n",
    "\n",
    "class BatchedGAT(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim=None, num_layers=3, heads=8, dropout=DROP):\n",
    "        super().__init__()\n",
    "        hid = hid_dim or in_dim\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_ch = in_dim if i==0 else hid\n",
    "            self.convs.append(GATConv(in_ch, hid//heads, heads=heads, concat=True, dropout=dropout))\n",
    "        self.proj = nn.Linear(hid, in_dim)\n",
    "        self.norm = nn.LayerNorm(in_dim)\n",
    "        self.act = nn.GELU()\n",
    "    def forward(self, pyg_batch: PyGBatch, T_per_sample: int):\n",
    "        x = pyg_batch.x; edge_index = pyg_batch.edge_index\n",
    "        h = x\n",
    "        for conv in self.convs:\n",
    "            h = conv(h, edge_index); h = self.act(h)\n",
    "        h = self.proj(h)\n",
    "        node_feats, mask = to_dense_batch(h, batch=pyg_batch.batch)  # (B, max_nodes, D)\n",
    "        B, max_nodes, D = node_feats.shape\n",
    "        if max_nodes < T_per_sample:\n",
    "            pad = torch.zeros(B, T_per_sample - max_nodes, D, device=node_feats.device)\n",
    "            node_feats = torch.cat([node_feats, pad], dim=1)\n",
    "        elif max_nodes > T_per_sample:\n",
    "            node_feats = node_feats[:, :T_per_sample, :]\n",
    "        return self.norm(node_feats)  # (B, T_per_sample, D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3014e0b",
   "metadata": {},
   "source": [
    "### Encoder, Decoder, AnticipationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d303d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleTransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, nhead=8, num_layers=3, dim_feedforward=2048, dropout=DROP, max_len=1000):\n",
    "        super().__init__()\n",
    "        enc = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, activation='gelu', batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(enc, num_layers=num_layers)\n",
    "        self.pos_emb = nn.Parameter(torch.randn(1, max_len, d_model))\n",
    "    def forward(self, x):\n",
    "        B,T,D = x.shape\n",
    "        pos = self.pos_emb[:, :T, :].to(x.device)\n",
    "        return self.encoder(x + pos)\n",
    "\n",
    "class AnticipationModel(nn.Module):\n",
    "    def __init__(self, feat_dim, num_classes: dict, k_fut=5, gat_layers=3, gat_heads=8, dec_layers=3, dec_heads=8, dropout=DROP):\n",
    "        super().__init__()\n",
    "        self.feat_dim = feat_dim; self.k_fut = k_fut\n",
    "        self.gat = BatchedGAT(in_dim=feat_dim, hid_dim=feat_dim, num_layers=gat_layers, heads=gat_heads, dropout=dropout)\n",
    "        self.encoder = SimpleTransformerEncoder(d_model=feat_dim, nhead=dec_heads, num_layers=3)\n",
    "        dec_layer = nn.TransformerDecoderLayer(d_model=feat_dim, nhead=dec_heads, dim_feedforward=feat_dim*4, dropout=dropout, activation='gelu', batch_first=True)\n",
    "        self.decoder = nn.TransformerDecoder(dec_layer, num_layers=dec_layers)\n",
    "        self.queries = nn.Parameter(torch.randn(1, k_fut, feat_dim))\n",
    "        assert isinstance(num_classes, dict)\n",
    "        self.verb_head = nn.Linear(feat_dim, num_classes[\"verb\"])\n",
    "        self.noun_head = nn.Linear(feat_dim, num_classes[\"noun\"])\n",
    "        self.action_head = nn.Linear(feat_dim, num_classes[\"action\"])\n",
    "\n",
    "    def forward(self, F_batch):\n",
    "        # F_batch: (B, T, D)\n",
    "        B,T,D = F_batch.shape; device = F_batch.device\n",
    "        data_list=[]\n",
    "        for b in range(B):\n",
    "            x = F_batch[b]\n",
    "            edge_index = build_topk_edge_index(x, k=K, device=device)\n",
    "            data_list.append(PyGData(x=x, edge_index=edge_index))\n",
    "        pyg_batch = PyGBatch.from_data_list(data_list).to(device)\n",
    "        gat_out = self.gat(pyg_batch, T_per_sample=T)   # (B,T,D)\n",
    "        enc_out = self.encoder(F_batch)                 # (B,T,D)\n",
    "        U = enc_out + gat_out\n",
    "        q = self.queries.expand(B, -1, -1).to(device)\n",
    "        dec_out = self.decoder(tgt=q, memory=U)         # (B, K_fut, D)\n",
    "        logits = {\n",
    "            \"verb\": self.verb_head(dec_out),\n",
    "            \"noun\": self.noun_head(dec_out),\n",
    "            \"action\": self.action_head(dec_out)\n",
    "        }\n",
    "        return logits, dec_out, gat_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe11752b",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bee06969",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma: float = 2.0, reduction: str = 'mean', ignore_index: int = -1, eps: float = 1e-8):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.ignore_index = ignore_index\n",
    "        self.eps = eps\n",
    "    def forward(self, logits: torch.Tensor, target: torch.Tensor):\n",
    "        B, K, C = logits.shape\n",
    "        logits_flat = logits.view(-1, C)\n",
    "        target_flat = target.view(-1)\n",
    "        mask = (target_flat != self.ignore_index)\n",
    "        if int(mask.sum().item()) == 0:\n",
    "            return logits.new_tensor(0.0)\n",
    "        probs = F.softmax(logits_flat, dim=-1)\n",
    "        idx = target_flat.clamp_min(0).long()\n",
    "        pt = probs[torch.arange(probs.size(0), device=probs.device), idx]\n",
    "        pt = torch.clamp(pt, min=self.eps)\n",
    "        loss = -((1.0 - pt) ** self.gamma) * torch.log(pt)\n",
    "        loss = loss[mask]\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "def temporal_smoothness_loss(dec_outs: torch.Tensor):\n",
    "    if dec_outs is None:\n",
    "        return torch.tensor(0.0)\n",
    "    diff = dec_outs[:, 1:, :] - dec_outs[:, :-1, :]\n",
    "    return diff.pow(2).mean()\n",
    "\n",
    "def supervised_contrastive_loss(features: torch.Tensor, labels: torch.Tensor, temperature: float = 0.07):\n",
    "    device = features.device\n",
    "    features = F.normalize(features, dim=1)\n",
    "    logits = torch.matmul(features, features.t()) / temperature  # (N, N)\n",
    "    logits_max, _ = logits.max(dim=1, keepdim=True)\n",
    "    logits = logits - logits_max.detach()\n",
    "    labels = labels.contiguous().view(-1, 1)\n",
    "    mask = torch.eq(labels, labels.t()).float().to(device)\n",
    "    diag = torch.eye(mask.size(0), device=device)\n",
    "    mask_non_self = mask * (1.0 - diag)\n",
    "    exp_logits = torch.exp(logits) * (1.0 - diag)\n",
    "    log_prob = logits - torch.log(exp_logits.sum(dim=1, keepdim=True) + 1e-12)\n",
    "    mean_log_prob_pos = (mask_non_self * log_prob).sum(1) / (mask_non_self.sum(1) + 1e-12)\n",
    "    loss = - mean_log_prob_pos\n",
    "    loss = loss.mean()\n",
    "    return loss\n",
    "\n",
    "def build_batch_adjacency_from_features(features_batch: torch.Tensor, k: int, symmetric: bool = True):\n",
    "    device = features_batch.device\n",
    "    B, T, D = features_batch.shape\n",
    "    N = B * T\n",
    "    A_blocks = torch.zeros((N, N), dtype=torch.float32, device=device)\n",
    "    for b in range(B):\n",
    "        feats = features_batch[b]  # (T, D)\n",
    "        x = F.normalize(feats, dim=1)\n",
    "        sim = torch.matmul(x, x.t())\n",
    "        sim.fill_diagonal_(-1.0)\n",
    "        kk = min(k, max(0, T-1))\n",
    "        if kk <= 0:\n",
    "            continue\n",
    "        vals, idxs = torch.topk(sim, kk, dim=1)\n",
    "        for i in range(T):\n",
    "            neighbors = idxs[i]\n",
    "            for nbr in neighbors.tolist():\n",
    "                A_blocks[b*T + i, b*T + nbr] = 1.0\n",
    "                if symmetric:\n",
    "                    A_blocks[b*T + nbr, b*T + i] = 1.0\n",
    "    return A_blocks\n",
    "\n",
    "def graph_reconstruction_loss(gat_out: torch.Tensor, features_batch: torch.Tensor, k: int):\n",
    "    if gat_out is None:\n",
    "        return torch.tensor(0.0, device=features_batch.device)\n",
    "    B, T, D = gat_out.shape\n",
    "    losses = []\n",
    "    for b in range(B):\n",
    "        emb = F.normalize(gat_out[b], dim=1)  # (T, D)\n",
    "        A_hat = torch.sigmoid(torch.matmul(emb, emb.t()))  # (T, T)\n",
    "        A_gt_block = build_batch_adjacency_from_features(features_batch[b:b+1].detach(), k=k)\n",
    "        A_gt = A_gt_block.to(A_hat.device)\n",
    "        losses.append(F.binary_cross_entropy(A_hat, A_gt))\n",
    "    return torch.stack(losses).mean() if len(losses) > 0 else torch.tensor(0.0, device=gat_out.device)\n",
    "\n",
    "# -------------------------\n",
    "# masked CE & metrics helpers\n",
    "# -------------------------\n",
    "def masked_cross_entropy(logits, labels, ignore_index=IGNORE_INDEX):\n",
    "    B, K, C = logits.shape\n",
    "    logits_flat = logits.view(B * K, C)      # (B*K, C)\n",
    "    labels_flat = labels.view(B * K)         # (B*K,)\n",
    "    loss_flat = F.cross_entropy(logits_flat, labels_flat, reduction='none', ignore_index=ignore_index)\n",
    "    mask = (labels_flat != ignore_index).float()\n",
    "    valid = mask.sum()\n",
    "    if valid == 0:\n",
    "        return (logits_flat * 0.0).sum()\n",
    "    return (loss_flat * mask).sum() / valid\n",
    "\n",
    "def topk_accuracy_per_task(logits, labels, topk=(1,5), ignore_index=IGNORE_INDEX):\n",
    "    B,K,C = logits.shape\n",
    "    res = {}\n",
    "    overall = {k:0 for k in topk}\n",
    "    total_cnt = 0\n",
    "    preds_topk = logits.topk(max(topk), dim=-1)[1]  # (B,K,maxk)\n",
    "    for h in range(K):\n",
    "        lab = labels[:,h]; mask = (lab != ignore_index); cnt = int(mask.sum().item())\n",
    "        for k in topk:\n",
    "            if cnt == 0:\n",
    "                res.setdefault(f\"per_h{h+1}_top{k}\", None)\n",
    "                continue\n",
    "            predk = preds_topk[:,h,:k]  # (B,k)\n",
    "            lab_exp = lab.unsqueeze(1).expand(-1, k)\n",
    "            hits = (predk == lab_exp)\n",
    "            hit = int(hits[mask].any(dim=1).float().sum().item())\n",
    "            res[f\"per_h{h+1}_top{k}\"] = hit / cnt\n",
    "            overall[k] += hit\n",
    "        total_cnt += cnt\n",
    "    for k in topk:\n",
    "        res[f\"overall_top{k}\"] = overall[k] / total_cnt if total_cnt>0 else None\n",
    "    return res\n",
    "\n",
    "def topk_counts(logits, labels, k):\n",
    "    with torch.no_grad():\n",
    "        B, K, C = logits.shape\n",
    "        topk_preds = logits.topk(k, dim=-1)[1]  # (B, K, k)\n",
    "        hits = 0\n",
    "        total = 0\n",
    "        for h in range(K):\n",
    "            lab = labels[:, h]  # (B,)\n",
    "            mask = (lab != IGNORE_INDEX)\n",
    "            if int(mask.sum().item()) == 0:\n",
    "                continue\n",
    "            predk = topk_preds[:, h, :]  # (B, k)\n",
    "            lab_exp = lab.unsqueeze(1).expand(-1, k)\n",
    "            masked_pred = predk[mask]\n",
    "            masked_lab = lab_exp[mask]\n",
    "            hit_vec = (masked_pred == masked_lab).any(dim=1).float()\n",
    "            hits += int(hit_vec.sum().item())\n",
    "            total += int(mask.sum().item())\n",
    "        return hits, total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4059f53f",
   "metadata": {},
   "source": [
    "### MAIN: Prepare dataset, model, and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c4c2f28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected num_classes: {'verb': 81, 'noun': 332, 'action': 123}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b917051a5194b799954edbbdd01b01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PAWANESH\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:5560: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f848064e724d079b3160fad70dfced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Time 12.0s\n",
      "  Train Loss: 9.0053 | Val Loss: 8.8257\n",
      "  VERB   Train Top1: 0.1508828250401284, Top5: 0.5971107544141252; Val Top1: 0.2440944881889764, Top5: 0.6719160104986877\n",
      "  NOUN   Train Top1: 0.10914927768860354, Top5: 0.32102728731942215; Val Top1: 0.015748031496062992, Top5: 0.17060367454068243\n",
      "  ACTION Train Top1: 0.0449438202247191, Top5: 0.1781701444622793; Val Top1: 0.0, Top5: 0.03937007874015748\n",
      "  VERB   Val Precision: 0.0163, Recall: 0.0667, F1: 0.0262\n",
      "  NOUN   Val Precision: 0.0005, Recall: 0.0323, F1: 0.0010\n",
      "  ACTION Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6650958135107943\n",
      "     NOUN    Mean Top-5 Recall: 0.17193746116259995\n",
      "     ACTION  Mean Top-5 Recall: 0.04016004372325099\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.17647058823529413  Top5: 0.6176470588235294\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.6216216216216216\n",
      "    @ 0.75s  Top1: 0.2727272727272727  Top5: 0.6363636363636364\n",
      "    @ 1.00s  Top1: 0.25  Top5: 0.6458333333333334\n",
      "    @ 1.25s  Top1: 0.25  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7272727272727273\n",
      "    @ 1.75s  Top1: 0.2631578947368421  Top5: 0.7192982456140351\n",
      "    @ 2.00s  Top1: 0.2413793103448276  Top5: 0.7068965517241379\n",
      "    overall_top1: 0.2440944881889764, overall_top5: 0.6719160104986877\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.029411764705882353  Top5: 0.20588235294117646\n",
      "    @ 0.50s  Top1: 0.02702702702702703  Top5: 0.1891891891891892\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.1590909090909091\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.14583333333333334\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.14583333333333334\n",
      "    @ 1.50s  Top1: 0.01818181818181818  Top5: 0.18181818181818182\n",
      "    @ 1.75s  Top1: 0.017543859649122806  Top5: 0.17543859649122806\n",
      "    @ 2.00s  Top1: 0.034482758620689655  Top5: 0.1724137931034483\n",
      "    overall_top1: 0.015748031496062992, overall_top5: 0.17060367454068243\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.058823529411764705\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.05405405405405406\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.022727272727272728\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.020833333333333332\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.041666666666666664\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.03636363636363636\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.03508771929824561\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.05172413793103448\n",
      "    overall_top1: 0.0, overall_top5: 0.03937007874015748\n",
      "[SAVED BEST] -> Model\\P01_05_best_model.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5a60a1804e4a5a8eae0bc588fed472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729e941f07a44384a186e8dc246c0071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | Time 11.4s\n",
      "  Train Loss: 7.7290 | Val Loss: 8.7477\n",
      "  VERB   Train Top1: 0.19743178170144463, Top5: 0.7062600321027287; Val Top1: 0.05511811023622047, Top5: 0.6272965879265092\n",
      "  NOUN   Train Top1: 0.12359550561797752, Top5: 0.36597110754414125; Val Top1: 0.015748031496062992, Top5: 0.30971128608923887\n",
      "  ACTION Train Top1: 0.02247191011235955, Top5: 0.18619582664526485; Val Top1: 0.005249343832020997, Top5: 0.023622047244094488\n",
      "  VERB   Val Precision: 0.0037, Recall: 0.0667, F1: 0.0070\n",
      "  NOUN   Val Precision: 0.0005, Recall: 0.0323, F1: 0.0010\n",
      "  ACTION Val Precision: 0.0003, Recall: 0.0062, F1: 0.0005\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6194906940299676\n",
      "     NOUN    Mean Top-5 Recall: 0.3082541353934609\n",
      "     ACTION  Mean Top-5 Recall: 0.022451785665728228\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.058823529411764705  Top5: 0.5588235294117647\n",
      "    @ 0.50s  Top1: 0.05405405405405406  Top5: 0.5675675675675675\n",
      "    @ 0.75s  Top1: 0.045454545454545456  Top5: 0.5909090909090909\n",
      "    @ 1.00s  Top1: 0.0625  Top5: 0.6041666666666666\n",
      "    @ 1.25s  Top1: 0.0625  Top5: 0.6041666666666666\n",
      "    @ 1.50s  Top1: 0.05454545454545454  Top5: 0.6909090909090909\n",
      "    @ 1.75s  Top1: 0.05263157894736842  Top5: 0.6842105263157895\n",
      "    @ 2.00s  Top1: 0.05172413793103448  Top5: 0.6551724137931034\n",
      "    overall_top1: 0.05511811023622047, overall_top5: 0.6272965879265092\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.029411764705882353  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.02702702702702703  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.29545454545454547\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.2708333333333333\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.2916666666666667\n",
      "    @ 1.50s  Top1: 0.01818181818181818  Top5: 0.3090909090909091\n",
      "    @ 1.75s  Top1: 0.017543859649122806  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.034482758620689655  Top5: 0.3448275862068966\n",
      "    overall_top1: 0.015748031496062992, overall_top5: 0.30971128608923887\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.029411764705882353  Top5: 0.029411764705882353\n",
      "    @ 0.50s  Top1: 0.02702702702702703  Top5: 0.02702702702702703\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.03636363636363636\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.03508771929824561\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.05172413793103448\n",
      "    overall_top1: 0.005249343832020997, overall_top5: 0.023622047244094488\n",
      "[SAVED BEST] -> Model\\P01_05_best_model.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54688da28d741089e722f24b73aa2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6995c021cac4727bcd9a30172a7ddc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 | Time 11.6s\n",
      "  Train Loss: 6.9743 | Val Loss: 8.8058\n",
      "  VERB   Train Top1: 0.17335473515248795, Top5: 0.6918138041733547; Val Top1: 0.26246719160104987, Top5: 0.6272965879265092\n",
      "  NOUN   Train Top1: 0.1187800963081862, Top5: 0.42375601926163725; Val Top1: 0.015748031496062992, Top5: 0.28608923884514437\n",
      "  ACTION Train Top1: 0.06741573033707865, Top5: 0.2712680577849117; Val Top1: 0.015748031496062992, Top5: 0.015748031496062992\n",
      "  VERB   Val Precision: 0.0175, Recall: 0.0667, F1: 0.0277\n",
      "  NOUN   Val Precision: 0.0005, Recall: 0.0323, F1: 0.0011\n",
      "  ACTION Val Precision: 0.0003, Recall: 0.0192, F1: 0.0006\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6194906940299676\n",
      "     NOUN    Mean Top-5 Recall: 0.2886414244659948\n",
      "     ACTION  Mean Top-5 Recall: 0.015830903523067503\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.2647058823529412  Top5: 0.5588235294117647\n",
      "    @ 0.50s  Top1: 0.2702702702702703  Top5: 0.5675675675675675\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.5909090909090909\n",
      "    @ 1.00s  Top1: 0.25  Top5: 0.6041666666666666\n",
      "    @ 1.25s  Top1: 0.25  Top5: 0.6041666666666666\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.6909090909090909\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.6842105263157895\n",
      "    @ 2.00s  Top1: 0.25862068965517243  Top5: 0.6551724137931034\n",
      "    overall_top1: 0.26246719160104987, overall_top5: 0.6272965879265092\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.029411764705882353  Top5: 0.35294117647058826\n",
      "    @ 0.50s  Top1: 0.02702702702702703  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.29545454545454547\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.25\n",
      "    @ 1.50s  Top1: 0.01818181818181818  Top5: 0.2545454545454545\n",
      "    @ 1.75s  Top1: 0.017543859649122806  Top5: 0.3157894736842105\n",
      "    @ 2.00s  Top1: 0.034482758620689655  Top5: 0.29310344827586204\n",
      "    overall_top1: 0.015748031496062992, overall_top5: 0.28608923884514437\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.029411764705882353  Top5: 0.029411764705882353\n",
      "    @ 0.50s  Top1: 0.02702702702702703  Top5: 0.02702702702702703\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.01818181818181818  Top5: 0.01818181818181818\n",
      "    @ 1.75s  Top1: 0.017543859649122806  Top5: 0.017543859649122806\n",
      "    @ 2.00s  Top1: 0.034482758620689655  Top5: 0.034482758620689655\n",
      "    overall_top1: 0.015748031496062992, overall_top5: 0.015748031496062992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5744302bee4445a9a2eba1cb9463584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09523b9f54684770927479e6665ad011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 | Time 10.8s\n",
      "  Train Loss: 6.6533 | Val Loss: 8.9167\n",
      "  VERB   Train Top1: 0.18940609951845908, Top5: 0.7191011235955056; Val Top1: 0.06561679790026247, Top5: 0.6272965879265092\n",
      "  NOUN   Train Top1: 0.15730337078651685, Top5: 0.42696629213483145; Val Top1: 0.05774278215223097, Top5: 0.2178477690288714\n",
      "  ACTION Train Top1: 0.0754414125200642, Top5: 0.2825040128410915; Val Top1: 0.0, Top5: 0.015748031496062992\n",
      "  VERB   Val Precision: 0.0097, Recall: 0.0548, F1: 0.0134\n",
      "  NOUN   Val Precision: 0.0231, Recall: 0.0458, F1: 0.0183\n",
      "  ACTION Val Precision: 0.0000, Recall: 0.0000, F1: 0.0000\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6194906940299676\n",
      "     NOUN    Mean Top-5 Recall: 0.21779435049658974\n",
      "     ACTION  Mean Top-5 Recall: 0.015830903523067503\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.08823529411764706  Top5: 0.5588235294117647\n",
      "    @ 0.50s  Top1: 0.08108108108108109  Top5: 0.5675675675675675\n",
      "    @ 0.75s  Top1: 0.045454545454545456  Top5: 0.5909090909090909\n",
      "    @ 1.00s  Top1: 0.0625  Top5: 0.6041666666666666\n",
      "    @ 1.25s  Top1: 0.08333333333333333  Top5: 0.6041666666666666\n",
      "    @ 1.50s  Top1: 0.07272727272727272  Top5: 0.6909090909090909\n",
      "    @ 1.75s  Top1: 0.05263157894736842  Top5: 0.6842105263157895\n",
      "    @ 2.00s  Top1: 0.05172413793103448  Top5: 0.6551724137931034\n",
      "    overall_top1: 0.06561679790026247, overall_top5: 0.6272965879265092\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.08823529411764706  Top5: 0.23529411764705882\n",
      "    @ 0.50s  Top1: 0.08108108108108109  Top5: 0.21621621621621623\n",
      "    @ 0.75s  Top1: 0.045454545454545456  Top5: 0.22727272727272727\n",
      "    @ 1.00s  Top1: 0.041666666666666664  Top5: 0.20833333333333334\n",
      "    @ 1.25s  Top1: 0.041666666666666664  Top5: 0.16666666666666666\n",
      "    @ 1.50s  Top1: 0.05454545454545454  Top5: 0.23636363636363636\n",
      "    @ 1.75s  Top1: 0.05263157894736842  Top5: 0.22807017543859648\n",
      "    @ 2.00s  Top1: 0.06896551724137931  Top5: 0.22413793103448276\n",
      "    overall_top1: 0.05774278215223097, overall_top5: 0.2178477690288714\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.0  Top5: 0.029411764705882353\n",
      "    @ 0.50s  Top1: 0.0  Top5: 0.02702702702702703\n",
      "    @ 0.75s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.00s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.25s  Top1: 0.0  Top5: 0.0\n",
      "    @ 1.50s  Top1: 0.0  Top5: 0.01818181818181818\n",
      "    @ 1.75s  Top1: 0.0  Top5: 0.017543859649122806\n",
      "    @ 2.00s  Top1: 0.0  Top5: 0.034482758620689655\n",
      "    overall_top1: 0.0, overall_top5: 0.015748031496062992\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244a41c10f2d47fb87e801f193b7e963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b00eaddbd5a4782bf856a155ecd2b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 | Time 10.5s\n",
      "  Train Loss: 6.5472 | Val Loss: 8.6198\n",
      "  VERB   Train Top1: 0.21829855537720708, Top5: 0.723916532905297; Val Top1: 0.24671916010498687, Top5: 0.6614173228346457\n",
      "  NOUN   Train Top1: 0.2247191011235955, Top5: 0.48796147672552165; Val Top1: 0.06561679790026247, Top5: 0.2047244094488189\n",
      "  ACTION Train Top1: 0.12680577849117175, Top5: 0.33707865168539325; Val Top1: 0.04199475065616798, Top5: 0.12860892388451445\n",
      "  VERB   Val Precision: 0.0307, Recall: 0.0637, F1: 0.0397\n",
      "  NOUN   Val Precision: 0.0396, Recall: 0.0566, F1: 0.0313\n",
      "  ACTION Val Precision: 0.0117, Recall: 0.0175, F1: 0.0140\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6541355819920195\n",
      "     NOUN    Mean Top-5 Recall: 0.20537409531317669\n",
      "     ACTION  Mean Top-5 Recall: 0.12946688012427443\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.5882352941176471\n",
      "    @ 0.50s  Top1: 0.21621621621621623  Top5: 0.6216216216216216\n",
      "    @ 0.75s  Top1: 0.22727272727272727  Top5: 0.6363636363636364\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.625\n",
      "    @ 1.25s  Top1: 0.25  Top5: 0.625\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7454545454545455\n",
      "    @ 1.75s  Top1: 0.2631578947368421  Top5: 0.7017543859649122\n",
      "    @ 2.00s  Top1: 0.25862068965517243  Top5: 0.6896551724137931\n",
      "    overall_top1: 0.24671916010498687, overall_top5: 0.6614173228346457\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.11764705882352941  Top5: 0.23529411764705882\n",
      "    @ 0.50s  Top1: 0.10810810810810811  Top5: 0.21621621621621623\n",
      "    @ 0.75s  Top1: 0.045454545454545456  Top5: 0.18181818181818182\n",
      "    @ 1.00s  Top1: 0.041666666666666664  Top5: 0.1875\n",
      "    @ 1.25s  Top1: 0.0625  Top5: 0.1875\n",
      "    @ 1.50s  Top1: 0.05454545454545454  Top5: 0.2\n",
      "    @ 1.75s  Top1: 0.07017543859649122  Top5: 0.21052631578947367\n",
      "    @ 2.00s  Top1: 0.05172413793103448  Top5: 0.22413793103448276\n",
      "    overall_top1: 0.06561679790026247, overall_top5: 0.2047244094488189\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.058823529411764705  Top5: 0.14705882352941177\n",
      "    @ 0.50s  Top1: 0.05405405405405406  Top5: 0.13513513513513514\n",
      "    @ 0.75s  Top1: 0.045454545454545456  Top5: 0.13636363636363635\n",
      "    @ 1.00s  Top1: 0.041666666666666664  Top5: 0.10416666666666667\n",
      "    @ 1.25s  Top1: 0.041666666666666664  Top5: 0.125\n",
      "    @ 1.50s  Top1: 0.03636363636363636  Top5: 0.12727272727272726\n",
      "    @ 1.75s  Top1: 0.03508771929824561  Top5: 0.12280701754385964\n",
      "    @ 2.00s  Top1: 0.034482758620689655  Top5: 0.13793103448275862\n",
      "    overall_top1: 0.04199475065616798, overall_top5: 0.12860892388451445\n",
      "[SAVED BEST] -> Model\\P01_05_best_model.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4fb4eee64545e9be393218b5219201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece1e74bb2ca44ab8751cfacdb0ac547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 | Time 10.8s\n",
      "  Train Loss: 5.7454 | Val Loss: 8.6301\n",
      "  VERB   Train Top1: 0.22792937399678972, Top5: 0.7929373996789727; Val Top1: 0.2440944881889764, Top5: 0.6745406824146981\n",
      "  NOUN   Train Top1: 0.30658105939004815, Top5: 0.5698234349919743; Val Top1: 0.14960629921259844, Top5: 0.2755905511811024\n",
      "  ACTION Train Top1: 0.23274478330658105, Top5: 0.5040128410914928; Val Top1: 0.03674540682414698, Top5: 0.11286089238845144\n",
      "  VERB   Val Precision: 0.0681, Recall: 0.1182, F1: 0.0849\n",
      "  NOUN   Val Precision: 0.0700, Recall: 0.0792, F1: 0.0655\n",
      "  ACTION Val Precision: 0.0182, Recall: 0.0159, F1: 0.0170\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6688100941413768\n",
      "     NOUN    Mean Top-5 Recall: 0.27522009786325335\n",
      "     ACTION  Mean Top-5 Recall: 0.11381738952866315\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6216216216216216\n",
      "    @ 0.75s  Top1: 0.22727272727272727  Top5: 0.6363636363636364\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.25s  Top1: 0.2708333333333333  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.23636363636363636  Top5: 0.7272727272727273\n",
      "    @ 1.75s  Top1: 0.2631578947368421  Top5: 0.7368421052631579\n",
      "    @ 2.00s  Top1: 0.25862068965517243  Top5: 0.6896551724137931\n",
      "    overall_top1: 0.2440944881889764, overall_top5: 0.6745406824146981\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.2647058823529412\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.1590909090909091  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.14583333333333334  Top5: 0.2708333333333333\n",
      "    @ 1.25s  Top1: 0.14583333333333334  Top5: 0.25\n",
      "    @ 1.50s  Top1: 0.14545454545454545  Top5: 0.2545454545454545\n",
      "    @ 1.75s  Top1: 0.12280701754385964  Top5: 0.3157894736842105\n",
      "    @ 2.00s  Top1: 0.1206896551724138  Top5: 0.27586206896551724\n",
      "    overall_top1: 0.14960629921259844, overall_top5: 0.2755905511811024\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.058823529411764705  Top5: 0.14705882352941177\n",
      "    @ 0.50s  Top1: 0.05405405405405406  Top5: 0.13513513513513514\n",
      "    @ 0.75s  Top1: 0.022727272727272728  Top5: 0.09090909090909091\n",
      "    @ 1.00s  Top1: 0.041666666666666664  Top5: 0.08333333333333333\n",
      "    @ 1.25s  Top1: 0.041666666666666664  Top5: 0.08333333333333333\n",
      "    @ 1.50s  Top1: 0.01818181818181818  Top5: 0.12727272727272726\n",
      "    @ 1.75s  Top1: 0.03508771929824561  Top5: 0.12280701754385964\n",
      "    @ 2.00s  Top1: 0.034482758620689655  Top5: 0.1206896551724138\n",
      "    overall_top1: 0.03674540682414698, overall_top5: 0.11286089238845144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b858f1c8674401782c309447ad0551a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0520e4bc26b042ce8d031f69b4a1e3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 | Time 11.0s\n",
      "  Train Loss: 5.2387 | Val Loss: 8.3512\n",
      "  VERB   Train Top1: 0.27447833065810595, Top5: 0.8154093097913323; Val Top1: 0.13385826771653545, Top5: 0.7244094488188977\n",
      "  NOUN   Train Top1: 0.3563402889245586, Top5: 0.6324237560192616; Val Top1: 0.15748031496062992, Top5: 0.30971128608923887\n",
      "  ACTION Train Top1: 0.29373996789727125, Top5: 0.6035313001605136; Val Top1: 0.06036745406824147, Top5: 0.24671916010498687\n",
      "  VERB   Val Precision: 0.0783, Recall: 0.1039, F1: 0.0699\n",
      "  NOUN   Val Precision: 0.1130, Recall: 0.1044, F1: 0.0756\n",
      "  ACTION Val Precision: 0.0268, Recall: 0.0294, F1: 0.0251\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7174727171772984\n",
      "     NOUN    Mean Top-5 Recall: 0.31337565331206574\n",
      "     ACTION  Mean Top-5 Recall: 0.2480436087333973\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.14705882352941177  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.16216216216216217  Top5: 0.7027027027027027\n",
      "    @ 0.75s  Top1: 0.09090909090909091  Top5: 0.6818181818181818\n",
      "    @ 1.00s  Top1: 0.125  Top5: 0.6875\n",
      "    @ 1.25s  Top1: 0.16666666666666666  Top5: 0.7083333333333334\n",
      "    @ 1.50s  Top1: 0.12727272727272726  Top5: 0.7818181818181819\n",
      "    @ 1.75s  Top1: 0.10526315789473684  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.15517241379310345  Top5: 0.7586206896551724\n",
      "    overall_top1: 0.13385826771653545, overall_top5: 0.7244094488188977\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.35294117647058826\n",
      "    @ 0.50s  Top1: 0.21621621621621623  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.1590909090909091  Top5: 0.29545454545454547\n",
      "    @ 1.00s  Top1: 0.14583333333333334  Top5: 0.3125\n",
      "    @ 1.25s  Top1: 0.14583333333333334  Top5: 0.3125\n",
      "    @ 1.50s  Top1: 0.14545454545454545  Top5: 0.2909090909090909\n",
      "    @ 1.75s  Top1: 0.14035087719298245  Top5: 0.2982456140350877\n",
      "    @ 2.00s  Top1: 0.13793103448275862  Top5: 0.29310344827586204\n",
      "    overall_top1: 0.15748031496062992, overall_top5: 0.30971128608923887\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.11764705882352941  Top5: 0.29411764705882354\n",
      "    @ 0.50s  Top1: 0.10810810810810811  Top5: 0.2702702702702703\n",
      "    @ 0.75s  Top1: 0.045454545454545456  Top5: 0.22727272727272727\n",
      "    @ 1.00s  Top1: 0.0625  Top5: 0.22916666666666666\n",
      "    @ 1.25s  Top1: 0.0625  Top5: 0.1875\n",
      "    @ 1.50s  Top1: 0.05454545454545454  Top5: 0.2545454545454545\n",
      "    @ 1.75s  Top1: 0.03508771929824561  Top5: 0.24561403508771928\n",
      "    @ 2.00s  Top1: 0.034482758620689655  Top5: 0.27586206896551724\n",
      "    overall_top1: 0.06036745406824147, overall_top5: 0.24671916010498687\n",
      "[SAVED BEST] -> Model\\P01_05_best_model.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f6afac0bb3410fbdea4aa1b51d99e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7e64b8b89a41c785eda4f974fee37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 | Time 11.1s\n",
      "  Train Loss: 4.4822 | Val Loss: 8.1327\n",
      "  VERB   Train Top1: 0.3402889245585875, Top5: 0.884430176565008; Val Top1: 0.25984251968503935, Top5: 0.7611548556430446\n",
      "  NOUN   Train Top1: 0.39646869983948635, Top5: 0.7736757624398074; Val Top1: 0.1679790026246719, Top5: 0.4094488188976378\n",
      "  ACTION Train Top1: 0.40770465489566615, Top5: 0.78330658105939; Val Top1: 0.08136482939632546, Top5: 0.2677165354330709\n",
      "  VERB   Val Precision: 0.0746, Recall: 0.1205, F1: 0.0901\n",
      "  NOUN   Val Precision: 0.0491, Recall: 0.0844, F1: 0.0568\n",
      "  ACTION Val Precision: 0.0370, Recall: 0.0516, F1: 0.0384\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7564614173737292\n",
      "     NOUN    Mean Top-5 Recall: 0.40794679955997615\n",
      "     ACTION  Mean Top-5 Recall: 0.2713144974074301\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.2647058823529412  Top5: 0.7352941176470589\n",
      "    @ 0.50s  Top1: 0.2972972972972973  Top5: 0.7297297297297297\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.25  Top5: 0.7291666666666666\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.7291666666666666\n",
      "    @ 1.50s  Top1: 0.2545454545454545  Top5: 0.8181818181818182\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.8070175438596491\n",
      "    @ 2.00s  Top1: 0.25862068965517243  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.25984251968503935, overall_top5: 0.7611548556430446\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.4411764705882353\n",
      "    @ 0.50s  Top1: 0.21621621621621623  Top5: 0.40540540540540543\n",
      "    @ 0.75s  Top1: 0.18181818181818182  Top5: 0.38636363636363635\n",
      "    @ 1.00s  Top1: 0.16666666666666666  Top5: 0.375\n",
      "    @ 1.25s  Top1: 0.16666666666666666  Top5: 0.3333333333333333\n",
      "    @ 1.50s  Top1: 0.14545454545454545  Top5: 0.41818181818181815\n",
      "    @ 1.75s  Top1: 0.14035087719298245  Top5: 0.43859649122807015\n",
      "    @ 2.00s  Top1: 0.13793103448275862  Top5: 0.46551724137931033\n",
      "    overall_top1: 0.1679790026246719, overall_top5: 0.4094488188976378\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.11764705882352941  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.13513513513513514  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.09090909090909091  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.0625  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.0625  Top5: 0.25\n",
      "    @ 1.50s  Top1: 0.07272727272727272  Top5: 0.2727272727272727\n",
      "    @ 1.75s  Top1: 0.07017543859649122  Top5: 0.24561403508771928\n",
      "    @ 2.00s  Top1: 0.06896551724137931  Top5: 0.25862068965517243\n",
      "    overall_top1: 0.08136482939632546, overall_top5: 0.2677165354330709\n",
      "[SAVED BEST] -> Model\\P01_05_best_model.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bbe8a8c94cb4bdd822bda877b4c9cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d1a0a0e0d149da9a29c17d2a451ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 | Time 10.9s\n",
      "  Train Loss: 4.0011 | Val Loss: 8.0384\n",
      "  VERB   Train Top1: 0.3595505617977528, Top5: 0.9020866773675762; Val Top1: 0.27296587926509186, Top5: 0.7506561679790026\n",
      "  NOUN   Train Top1: 0.4622792937399679, Top5: 0.7688603531300161; Val Top1: 0.2388451443569554, Top5: 0.43832020997375326\n",
      "  ACTION Train Top1: 0.48796147672552165, Top5: 0.8330658105939005; Val Top1: 0.14173228346456693, Top5: 0.2755905511811024\n",
      "  VERB   Val Precision: 0.1393, Recall: 0.1312, F1: 0.1165\n",
      "  NOUN   Val Precision: 0.1333, Recall: 0.1560, F1: 0.1271\n",
      "  ACTION Val Precision: 0.0707, Recall: 0.1030, F1: 0.0787\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7437493671913711\n",
      "     NOUN    Mean Top-5 Recall: 0.44260403193526127\n",
      "     ACTION  Mean Top-5 Recall: 0.2779353795500908\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.3235294117647059  Top5: 0.6764705882352942\n",
      "    @ 0.50s  Top1: 0.2972972972972973  Top5: 0.7027027027027027\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7045454545454546\n",
      "    @ 1.00s  Top1: 0.2708333333333333  Top5: 0.75\n",
      "    @ 1.25s  Top1: 0.2708333333333333  Top5: 0.75\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.8181818181818182\n",
      "    @ 1.75s  Top1: 0.2631578947368421  Top5: 0.7894736842105263\n",
      "    @ 2.00s  Top1: 0.25862068965517243  Top5: 0.7586206896551724\n",
      "    overall_top1: 0.27296587926509186, overall_top5: 0.7506561679790026\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.2727272727272727  Top5: 0.4090909090909091\n",
      "    @ 1.00s  Top1: 0.25  Top5: 0.4166666666666667\n",
      "    @ 1.25s  Top1: 0.20833333333333334  Top5: 0.375\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.45454545454545453\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.43859649122807015\n",
      "    @ 2.00s  Top1: 0.1896551724137931  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.2388451443569554, overall_top5: 0.43832020997375326\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.13636363636363635  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.125  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.125  Top5: 0.25\n",
      "    @ 1.50s  Top1: 0.12727272727272726  Top5: 0.2909090909090909\n",
      "    @ 1.75s  Top1: 0.12280701754385964  Top5: 0.2631578947368421\n",
      "    @ 2.00s  Top1: 0.13793103448275862  Top5: 0.27586206896551724\n",
      "    overall_top1: 0.14173228346456693, overall_top5: 0.2755905511811024\n",
      "[SAVED BEST] -> Model\\P01_05_best_model.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff66e932a70645579a96d0cfdcc56ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d62f8252b74844aca10f0e73f6cb33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 | Time 10.9s\n",
      "  Train Loss: 3.2969 | Val Loss: 8.0135\n",
      "  VERB   Train Top1: 0.4654895666131621, Top5: 0.9373996789727127; Val Top1: 0.2230971128608924, Top5: 0.7716535433070866\n",
      "  NOUN   Train Top1: 0.5666131621187801, Top5: 0.8956661316211878; Val Top1: 0.2047244094488189, Top5: 0.4435695538057743\n",
      "  ACTION Train Top1: 0.593900481540931, Top5: 0.9117174959871589; Val Top1: 0.14173228346456693, Top5: 0.2782152230971129\n",
      "  VERB   Val Precision: 0.1388, Recall: 0.1527, F1: 0.1165\n",
      "  NOUN   Val Precision: 0.1039, Recall: 0.1281, F1: 0.1035\n",
      "  ACTION Val Precision: 0.0891, Recall: 0.1218, F1: 0.0902\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7641897849746881\n",
      "     NOUN    Mean Top-5 Recall: 0.4452002417711489\n",
      "     ACTION  Mean Top-5 Recall: 0.28012836200623115\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.17647058823529413  Top5: 0.6764705882352942\n",
      "    @ 0.50s  Top1: 0.16216216216216217  Top5: 0.7297297297297297\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.7708333333333334\n",
      "    @ 1.25s  Top1: 0.20833333333333334  Top5: 0.75\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.8363636363636363\n",
      "    @ 1.75s  Top1: 0.24561403508771928  Top5: 0.8070175438596491\n",
      "    @ 2.00s  Top1: 0.2413793103448276  Top5: 0.7931034482758621\n",
      "    overall_top1: 0.2230971128608924, overall_top5: 0.7716535433070866\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.29411764705882354  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.2702702702702703  Top5: 0.4594594594594595\n",
      "    @ 0.75s  Top1: 0.22727272727272727  Top5: 0.4090909090909091\n",
      "    @ 1.00s  Top1: 0.20833333333333334  Top5: 0.3958333333333333\n",
      "    @ 1.25s  Top1: 0.16666666666666666  Top5: 0.375\n",
      "    @ 1.50s  Top1: 0.18181818181818182  Top5: 0.43636363636363634\n",
      "    @ 1.75s  Top1: 0.17543859649122806  Top5: 0.47368421052631576\n",
      "    @ 2.00s  Top1: 0.1724137931034483  Top5: 0.4827586206896552\n",
      "    overall_top1: 0.2047244094488189, overall_top5: 0.4435695538057743\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.17647058823529413  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.16216216216216217  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.11363636363636363  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.10416666666666667  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.10416666666666667  Top5: 0.25\n",
      "    @ 1.50s  Top1: 0.16363636363636364  Top5: 0.2909090909090909\n",
      "    @ 1.75s  Top1: 0.15789473684210525  Top5: 0.2807017543859649\n",
      "    @ 2.00s  Top1: 0.15517241379310345  Top5: 0.27586206896551724\n",
      "    overall_top1: 0.14173228346456693, overall_top5: 0.2782152230971129\n",
      "[SAVED BEST] -> Model\\P01_05_best_model.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5980cd1be5d142fa8d888bbab0d74dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e584a429502413491e7991e7609917d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 | Time 10.6s\n",
      "  Train Loss: 2.5139 | Val Loss: 7.8821\n",
      "  VERB   Train Top1: 0.5842696629213483, Top5: 0.9486356340288925; Val Top1: 0.2230971128608924, Top5: 0.7585301837270341\n",
      "  NOUN   Train Top1: 0.6918138041733547, Top5: 0.9454253611556982; Val Top1: 0.27034120734908135, Top5: 0.4304461942257218\n",
      "  ACTION Train Top1: 0.7303370786516854, Top5: 0.9534510433386838; Val Top1: 0.14698162729658792, Top5: 0.28608923884514437\n",
      "  VERB   Val Precision: 0.1151, Recall: 0.1346, F1: 0.0998\n",
      "  NOUN   Val Precision: 0.1936, Recall: 0.1798, F1: 0.1636\n",
      "  ACTION Val Precision: 0.0823, Recall: 0.1059, F1: 0.0875\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7522852875403718\n",
      "     NOUN    Mean Top-5 Recall: 0.4333624224476085\n",
      "     ACTION  Mean Top-5 Recall: 0.2881529874643999\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.17647058823529413  Top5: 0.7058823529411765\n",
      "    @ 0.50s  Top1: 0.16216216216216217  Top5: 0.7027027027027027\n",
      "    @ 0.75s  Top1: 0.18181818181818182  Top5: 0.75\n",
      "    @ 1.00s  Top1: 0.20833333333333334  Top5: 0.7291666666666666\n",
      "    @ 1.25s  Top1: 0.25  Top5: 0.7291666666666666\n",
      "    @ 1.50s  Top1: 0.2545454545454545  Top5: 0.8181818181818182\n",
      "    @ 1.75s  Top1: 0.24561403508771928  Top5: 0.8245614035087719\n",
      "    @ 2.00s  Top1: 0.25862068965517243  Top5: 0.7586206896551724\n",
      "    overall_top1: 0.2230971128608924, overall_top5: 0.7585301837270341\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.35135135135135137  Top5: 0.43243243243243246\n",
      "    @ 0.75s  Top1: 0.2727272727272727  Top5: 0.4090909090909091\n",
      "    @ 1.00s  Top1: 0.2708333333333333  Top5: 0.4375\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.4166666666666667\n",
      "    @ 1.50s  Top1: 0.23636363636363636  Top5: 0.43636363636363634\n",
      "    @ 1.75s  Top1: 0.24561403508771928  Top5: 0.42105263157894735\n",
      "    @ 2.00s  Top1: 0.25862068965517243  Top5: 0.41379310344827586\n",
      "    overall_top1: 0.27034120734908135, overall_top5: 0.4304461942257218\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.17647058823529413  Top5: 0.35294117647058826\n",
      "    @ 0.50s  Top1: 0.16216216216216217  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.13636363636363635  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.125  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.125  Top5: 0.25\n",
      "    @ 1.50s  Top1: 0.16363636363636364  Top5: 0.2909090909090909\n",
      "    @ 1.75s  Top1: 0.15789473684210525  Top5: 0.2982456140350877\n",
      "    @ 2.00s  Top1: 0.13793103448275862  Top5: 0.29310344827586204\n",
      "    overall_top1: 0.14698162729658792, overall_top5: 0.28608923884514437\n",
      "[SAVED BEST] -> Model\\P01_05_best_model.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd5347947374ce7a34252e5637f54c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7136e3eafe425184250c70ef261a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 | Time 11.0s\n",
      "  Train Loss: 2.1195 | Val Loss: 7.5287\n",
      "  VERB   Train Top1: 0.6548956661316212, Top5: 0.9887640449438202; Val Top1: 0.4120734908136483, Top5: 0.8031496062992126\n",
      "  NOUN   Train Top1: 0.7672552166934189, Top5: 0.9791332263242376; Val Top1: 0.28083989501312334, Top5: 0.45144356955380577\n",
      "  ACTION Train Top1: 0.7784911717495987, Top5: 0.9807383627608347; Val Top1: 0.2073490813648294, Top5: 0.28608923884514437\n",
      "  VERB   Val Precision: 0.2110, Recall: 0.2305, F1: 0.2084\n",
      "  NOUN   Val Precision: 0.1530, Recall: 0.1860, F1: 0.1602\n",
      "  ACTION Val Precision: 0.0976, Recall: 0.1463, F1: 0.1090\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7958009270285746\n",
      "     NOUN    Mean Top-5 Recall: 0.45461486198498446\n",
      "     ACTION  Mean Top-5 Recall: 0.28716042835941813\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.7352941176470589\n",
      "    @ 0.50s  Top1: 0.2972972972972973  Top5: 0.7567567567567568\n",
      "    @ 0.75s  Top1: 0.4318181818181818  Top5: 0.7727272727272727\n",
      "    @ 1.00s  Top1: 0.4375  Top5: 0.7708333333333334\n",
      "    @ 1.25s  Top1: 0.3958333333333333  Top5: 0.7708333333333334\n",
      "    @ 1.50s  Top1: 0.45454545454545453  Top5: 0.8727272727272727\n",
      "    @ 1.75s  Top1: 0.43859649122807015  Top5: 0.8596491228070176\n",
      "    @ 2.00s  Top1: 0.43103448275862066  Top5: 0.8275862068965517\n",
      "    overall_top1: 0.4120734908136483, overall_top5: 0.8031496062992126\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.38235294117647056  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.35135135135135137  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.29545454545454547  Top5: 0.45454545454545453\n",
      "    @ 1.00s  Top1: 0.2916666666666667  Top5: 0.4375\n",
      "    @ 1.25s  Top1: 0.25  Top5: 0.4166666666666667\n",
      "    @ 1.50s  Top1: 0.2545454545454545  Top5: 0.45454545454545453\n",
      "    @ 1.75s  Top1: 0.24561403508771928  Top5: 0.45614035087719296\n",
      "    @ 2.00s  Top1: 0.2413793103448276  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.28083989501312334, overall_top5: 0.45144356955380577\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.21621621621621623  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.21818181818181817  Top5: 0.3090909090909091\n",
      "    @ 1.75s  Top1: 0.21052631578947367  Top5: 0.2807017543859649\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.29310344827586204\n",
      "    overall_top1: 0.2073490813648294, overall_top5: 0.28608923884514437\n",
      "[SAVED BEST] -> Model\\P01_05_best_model.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f75b4aefd8f4feea6ecfd5f024737bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b0e667c90d4a148dc5b1661fd23c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 | Time 10.7s\n",
      "  Train Loss: 1.7302 | Val Loss: 7.8411\n",
      "  VERB   Train Top1: 0.7126805778491172, Top5: 0.9919743178170144; Val Top1: 0.29658792650918636, Top5: 0.7112860892388452\n",
      "  NOUN   Train Top1: 0.8041733547351525, Top5: 0.9919743178170144; Val Top1: 0.2755905511811024, Top5: 0.4540682414698163\n",
      "  ACTION Train Top1: 0.8876404494382022, Top5: 0.9871589085072231; Val Top1: 0.18110236220472442, Top5: 0.28346456692913385\n",
      "  VERB   Val Precision: 0.2109, Recall: 0.1542, F1: 0.1370\n",
      "  NOUN   Val Precision: 0.1939, Recall: 0.1823, F1: 0.1780\n",
      "  ACTION Val Precision: 0.1163, Recall: 0.1447, F1: 0.1101\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7004090181524926\n",
      "     NOUN    Mean Top-5 Recall: 0.4589392592079885\n",
      "     ACTION  Mean Top-5 Recall: 0.28459407173509876\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6176470588235294\n",
      "    @ 0.50s  Top1: 0.2702702702702703  Top5: 0.6216216216216216\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.6590909090909091\n",
      "    @ 1.00s  Top1: 0.2916666666666667  Top5: 0.6875\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.6875\n",
      "    @ 1.50s  Top1: 0.36363636363636365  Top5: 0.7818181818181819\n",
      "    @ 1.75s  Top1: 0.3157894736842105  Top5: 0.7894736842105263\n",
      "    @ 2.00s  Top1: 0.3103448275862069  Top5: 0.7586206896551724\n",
      "    overall_top1: 0.29658792650918636, overall_top5: 0.7112860892388452\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.38235294117647056  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.35135135135135137  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.29545454545454547  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.2708333333333333  Top5: 0.4375\n",
      "    @ 1.25s  Top1: 0.25  Top5: 0.4166666666666667\n",
      "    @ 1.50s  Top1: 0.23636363636363636  Top5: 0.45454545454545453\n",
      "    @ 1.75s  Top1: 0.24561403508771928  Top5: 0.43859649122807015\n",
      "    @ 2.00s  Top1: 0.2413793103448276  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.2755905511811024, overall_top5: 0.4540682414698163\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.17647058823529413  Top5: 0.3235294117647059\n",
      "    @ 0.50s  Top1: 0.16216216216216217  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.1590909090909091  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.14583333333333334  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.14583333333333334  Top5: 0.25\n",
      "    @ 1.50s  Top1: 0.21818181818181817  Top5: 0.3090909090909091\n",
      "    @ 1.75s  Top1: 0.21052631578947367  Top5: 0.2982456140350877\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.27586206896551724\n",
      "    overall_top1: 0.18110236220472442, overall_top5: 0.28346456692913385\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984dc44086ab4d609bf489216a8c10a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06b0a3f263c43ccbb53dd39368f6a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 | Time 10.7s\n",
      "  Train Loss: 1.4029 | Val Loss: 7.7438\n",
      "  VERB   Train Top1: 0.8073836276083467, Top5: 0.9967897271268058; Val Top1: 0.25196850393700787, Top5: 0.7112860892388452\n",
      "  NOUN   Train Top1: 0.8747993579454254, Top5: 0.9919743178170144; Val Top1: 0.2388451443569554, Top5: 0.48293963254593175\n",
      "  ACTION Train Top1: 0.8940609951845907, Top5: 0.9935794542536116; Val Top1: 0.23622047244094488, Top5: 0.29396325459317585\n",
      "  VERB   Val Precision: 0.1771, Recall: 0.1678, F1: 0.1497\n",
      "  NOUN   Val Precision: 0.2394, Recall: 0.1720, F1: 0.1712\n",
      "  ACTION Val Precision: 0.1498, Recall: 0.1676, F1: 0.1431\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6988499099357032\n",
      "     NOUN    Mean Top-5 Recall: 0.482908855223397\n",
      "     ACTION  Mean Top-5 Recall: 0.2947360595647133\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.5882352941176471\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.6216216216216216\n",
      "    @ 0.75s  Top1: 0.22727272727272727  Top5: 0.6590909090909091\n",
      "    @ 1.00s  Top1: 0.25  Top5: 0.6875\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6875\n",
      "    @ 1.50s  Top1: 0.3090909090909091  Top5: 0.7818181818181819\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.7931034482758621\n",
      "    overall_top1: 0.25196850393700787, overall_top5: 0.7112860892388452\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.3235294117647059  Top5: 0.5\n",
      "    @ 0.50s  Top1: 0.2972972972972973  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.45454545454545453\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.20833333333333334  Top5: 0.4375\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.22807017543859648  Top5: 0.49122807017543857\n",
      "    @ 2.00s  Top1: 0.22413793103448276  Top5: 0.5172413793103449\n",
      "    overall_top1: 0.2388451443569554, overall_top5: 0.48293963254593175\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.35294117647058826\n",
      "    @ 0.50s  Top1: 0.21621621621621623  Top5: 0.2972972972972973\n",
      "    @ 0.75s  Top1: 0.22727272727272727  Top5: 0.2727272727272727\n",
      "    @ 1.00s  Top1: 0.1875  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.1875  Top5: 0.25\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.3090909090909091\n",
      "    @ 1.75s  Top1: 0.2631578947368421  Top5: 0.2982456140350877\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.3275862068965517\n",
      "    overall_top1: 0.23622047244094488, overall_top5: 0.29396325459317585\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02cadd1774f42879600229b24c65a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814b326099294cde9e00bf1cbc55fe47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 | Time 10.8s\n",
      "  Train Loss: 1.1285 | Val Loss: 7.6277\n",
      "  VERB   Train Top1: 0.884430176565008, Top5: 0.9935794542536116; Val Top1: 0.30183727034120733, Top5: 0.7401574803149606\n",
      "  NOUN   Train Top1: 0.9197431781701445, Top5: 0.9951845906902087; Val Top1: 0.28083989501312334, Top5: 0.4671916010498688\n",
      "  ACTION Train Top1: 0.942215088282504, Top5: 0.9967897271268058; Val Top1: 0.1889763779527559, Top5: 0.30446194225721784\n",
      "  VERB   Val Precision: 0.1861, Recall: 0.1821, F1: 0.1625\n",
      "  NOUN   Val Precision: 0.2249, Recall: 0.1937, F1: 0.1883\n",
      "  ACTION Val Precision: 0.1064, Recall: 0.1310, F1: 0.1080\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7283683065842175\n",
      "     NOUN    Mean Top-5 Recall: 0.4720468084990811\n",
      "     ACTION  Mean Top-5 Recall: 0.309144926930604\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.2647058823529412  Top5: 0.6176470588235294\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.29545454545454547  Top5: 0.7045454545454546\n",
      "    @ 1.00s  Top1: 0.3125  Top5: 0.7083333333333334\n",
      "    @ 1.25s  Top1: 0.3125  Top5: 0.7291666666666666\n",
      "    @ 1.50s  Top1: 0.32727272727272727  Top5: 0.8181818181818182\n",
      "    @ 1.75s  Top1: 0.3157894736842105  Top5: 0.8245614035087719\n",
      "    @ 2.00s  Top1: 0.3103448275862069  Top5: 0.7758620689655172\n",
      "    overall_top1: 0.30183727034120733, overall_top5: 0.7401574803149606\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.3235294117647059  Top5: 0.5588235294117647\n",
      "    @ 0.50s  Top1: 0.2972972972972973  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.3181818181818182  Top5: 0.45454545454545453\n",
      "    @ 1.00s  Top1: 0.2708333333333333  Top5: 0.4375\n",
      "    @ 1.25s  Top1: 0.2708333333333333  Top5: 0.4166666666666667\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2631578947368421  Top5: 0.45614035087719296\n",
      "    @ 2.00s  Top1: 0.25862068965517243  Top5: 0.4482758620689655\n",
      "    overall_top1: 0.28083989501312334, overall_top5: 0.4671916010498688\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.38235294117647056\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.18181818181818182  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.16666666666666666  Top5: 0.2708333333333333\n",
      "    @ 1.25s  Top1: 0.16666666666666666  Top5: 0.25\n",
      "    @ 1.50s  Top1: 0.2  Top5: 0.3090909090909091\n",
      "    @ 1.75s  Top1: 0.19298245614035087  Top5: 0.2982456140350877\n",
      "    @ 2.00s  Top1: 0.20689655172413793  Top5: 0.29310344827586204\n",
      "    overall_top1: 0.1889763779527559, overall_top5: 0.30446194225721784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f312e5dcd526459eb094ff507f7c8ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237ac5f099ff44b09f5e0e7343eb7466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 | Time 10.6s\n",
      "  Train Loss: 0.8482 | Val Loss: 7.6182\n",
      "  VERB   Train Top1: 0.9101123595505618, Top5: 0.9967897271268058; Val Top1: 0.2755905511811024, Top5: 0.7244094488188977\n",
      "  NOUN   Train Top1: 0.9486356340288925, Top5: 0.9983948635634029; Val Top1: 0.28608923884514437, Top5: 0.47244094488188976\n",
      "  ACTION Train Top1: 0.9598715890850722, Top5: 0.9983948635634029; Val Top1: 0.2152230971128609, Top5: 0.3123359580052493\n",
      "  VERB   Val Precision: 0.1774, Recall: 0.1714, F1: 0.1544\n",
      "  NOUN   Val Precision: 0.2070, Recall: 0.1902, F1: 0.1754\n",
      "  ACTION Val Precision: 0.1461, Recall: 0.1489, F1: 0.1285\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7138726238035982\n",
      "     NOUN    Mean Top-5 Recall: 0.4787780727132307\n",
      "     ACTION  Mean Top-5 Recall: 0.31458041315102675\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.17647058823529413  Top5: 0.6176470588235294\n",
      "    @ 0.50s  Top1: 0.16216216216216217  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.20454545454545456  Top5: 0.6590909090909091\n",
      "    @ 1.00s  Top1: 0.25  Top5: 0.7083333333333334\n",
      "    @ 1.25s  Top1: 0.25  Top5: 0.7291666666666666\n",
      "    @ 1.50s  Top1: 0.36363636363636365  Top5: 0.8\n",
      "    @ 1.75s  Top1: 0.3508771929824561  Top5: 0.7894736842105263\n",
      "    @ 2.00s  Top1: 0.3448275862068966  Top5: 0.7586206896551724\n",
      "    overall_top1: 0.2755905511811024, overall_top5: 0.7244094488188977\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5882352941176471\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.3181818181818182  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.2916666666666667  Top5: 0.4375\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.4375\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.45454545454545453\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.45614035087719296\n",
      "    @ 2.00s  Top1: 0.25862068965517243  Top5: 0.46551724137931033\n",
      "    overall_top1: 0.28608923884514437, overall_top5: 0.47244094488188976\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.38235294117647056\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.32432432432432434\n",
      "    @ 0.75s  Top1: 0.18181818181818182  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.16666666666666666  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.16666666666666666  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.2545454545454545  Top5: 0.32727272727272727\n",
      "    @ 1.75s  Top1: 0.24561403508771928  Top5: 0.3333333333333333\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.3103448275862069\n",
      "    overall_top1: 0.2152230971128609, overall_top5: 0.3123359580052493\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fb308475784c289dbe2719c4ec2d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff14fd3ea08469bacbc50ad15565ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 | Time 11.2s\n",
      "  Train Loss: 0.7391 | Val Loss: 7.7998\n",
      "  VERB   Train Top1: 0.9309791332263242, Top5: 0.9967897271268058; Val Top1: 0.2887139107611549, Top5: 0.7559055118110236\n",
      "  NOUN   Train Top1: 0.9743178170144462, Top5: 1.0; Val Top1: 0.30183727034120733, Top5: 0.4540682414698163\n",
      "  ACTION Train Top1: 0.971107544141252, Top5: 0.9983948635634029; Val Top1: 0.2073490813648294, Top5: 0.32020997375328086\n",
      "  VERB   Val Precision: 0.2675, Recall: 0.2433, F1: 0.2075\n",
      "  NOUN   Val Precision: 0.2405, Recall: 0.2099, F1: 0.2003\n",
      "  ACTION Val Precision: 0.1232, Recall: 0.1437, F1: 0.1231\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.747474086022147\n",
      "     NOUN    Mean Top-5 Recall: 0.4578801483626935\n",
      "     ACTION  Mean Top-5 Recall: 0.3216922243208007\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.23529411764705882  Top5: 0.6764705882352942\n",
      "    @ 0.50s  Top1: 0.24324324324324326  Top5: 0.7027027027027027\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7272727272727273\n",
      "    @ 1.00s  Top1: 0.25  Top5: 0.7083333333333334\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.7291666666666666\n",
      "    @ 1.50s  Top1: 0.32727272727272727  Top5: 0.8181818181818182\n",
      "    @ 1.75s  Top1: 0.3333333333333333  Top5: 0.8245614035087719\n",
      "    @ 2.00s  Top1: 0.3275862068965517  Top5: 0.7931034482758621\n",
      "    overall_top1: 0.2887139107611549, overall_top5: 0.7559055118110236\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5294117647058824\n",
      "    @ 0.50s  Top1: 0.35135135135135137  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.45454545454545453\n",
      "    @ 1.00s  Top1: 0.2916666666666667  Top5: 0.4375\n",
      "    @ 1.25s  Top1: 0.2708333333333333  Top5: 0.3958333333333333\n",
      "    @ 1.50s  Top1: 0.2909090909090909  Top5: 0.45454545454545453\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.47368421052631576\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.43103448275862066\n",
      "    overall_top1: 0.30183727034120733, overall_top5: 0.4540682414698163\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.38235294117647056\n",
      "    @ 0.50s  Top1: 0.16216216216216217  Top5: 0.32432432432432434\n",
      "    @ 0.75s  Top1: 0.18181818181818182  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.16666666666666666  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.20833333333333334  Top5: 0.2916666666666667\n",
      "    @ 1.50s  Top1: 0.2545454545454545  Top5: 0.36363636363636365\n",
      "    @ 1.75s  Top1: 0.22807017543859648  Top5: 0.3157894736842105\n",
      "    @ 2.00s  Top1: 0.22413793103448276  Top5: 0.3275862068965517\n",
      "    overall_top1: 0.2073490813648294, overall_top5: 0.32020997375328086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6621cacfee4381924a583744245fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f3c02c0a634af68f38fa1031fe4fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 | Time 10.9s\n",
      "  Train Loss: 0.5870 | Val Loss: 7.6714\n",
      "  VERB   Train Top1: 0.9550561797752809, Top5: 0.9983948635634029; Val Top1: 0.27296587926509186, Top5: 0.7322834645669292\n",
      "  NOUN   Train Top1: 0.9775280898876404, Top5: 0.9983948635634029; Val Top1: 0.30183727034120733, Top5: 0.5039370078740157\n",
      "  ACTION Train Top1: 0.9887640449438202, Top5: 0.9983948635634029; Val Top1: 0.2099737532808399, Top5: 0.32020997375328086\n",
      "  VERB   Val Precision: 0.2024, Recall: 0.1861, F1: 0.1708\n",
      "  NOUN   Val Precision: 0.2366, Recall: 0.2159, F1: 0.2045\n",
      "  ACTION Val Precision: 0.1280, Recall: 0.1349, F1: 0.1186\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7228197283631255\n",
      "     NOUN    Mean Top-5 Recall: 0.5067513113510698\n",
      "     ACTION  Mean Top-5 Recall: 0.3232090596369781\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.6470588235294118\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.25  Top5: 0.7045454545454546\n",
      "    @ 1.00s  Top1: 0.25  Top5: 0.7083333333333334\n",
      "    @ 1.25s  Top1: 0.2916666666666667  Top5: 0.7083333333333334\n",
      "    @ 1.50s  Top1: 0.2909090909090909  Top5: 0.8\n",
      "    @ 1.75s  Top1: 0.3157894736842105  Top5: 0.8070175438596491\n",
      "    @ 2.00s  Top1: 0.3275862068965517  Top5: 0.7586206896551724\n",
      "    overall_top1: 0.27296587926509186, overall_top5: 0.7322834645669292\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.6176470588235294\n",
      "    @ 0.50s  Top1: 0.35135135135135137  Top5: 0.4864864864864865\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.2708333333333333  Top5: 0.4791666666666667\n",
      "    @ 1.50s  Top1: 0.2909090909090909  Top5: 0.509090909090909\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.5172413793103449\n",
      "    overall_top1: 0.30183727034120733, overall_top5: 0.5039370078740157\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.38235294117647056\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.35135135135135137\n",
      "    @ 0.75s  Top1: 0.18181818181818182  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.16666666666666666  Top5: 0.2708333333333333\n",
      "    @ 1.25s  Top1: 0.20833333333333334  Top5: 0.2916666666666667\n",
      "    @ 1.50s  Top1: 0.23636363636363636  Top5: 0.34545454545454546\n",
      "    @ 1.75s  Top1: 0.22807017543859648  Top5: 0.2982456140350877\n",
      "    @ 2.00s  Top1: 0.2413793103448276  Top5: 0.3275862068965517\n",
      "    overall_top1: 0.2099737532808399, overall_top5: 0.32020997375328086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbaff01cbbbc4010b742bba63c3bf2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7469bc3cad2244518de6b57be8c857d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 | Time 10.8s\n",
      "  Train Loss: 0.5449 | Val Loss: 7.7575\n",
      "  VERB   Train Top1: 0.9646869983948636, Top5: 0.9983948635634029; Val Top1: 0.2677165354330709, Top5: 0.7139107611548556\n",
      "  NOUN   Train Top1: 0.9791332263242376, Top5: 1.0; Val Top1: 0.30183727034120733, Top5: 0.49343832020997375\n",
      "  ACTION Train Top1: 0.985553772070626, Top5: 1.0; Val Top1: 0.2047244094488189, Top5: 0.31496062992125984\n",
      "  VERB   Val Precision: 0.2016, Recall: 0.1687, F1: 0.1667\n",
      "  NOUN   Val Precision: 0.2402, Recall: 0.2243, F1: 0.2060\n",
      "  ACTION Val Precision: 0.1327, Recall: 0.1391, F1: 0.1225\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.7038120134969447\n",
      "     NOUN    Mean Top-5 Recall: 0.4973835352331669\n",
      "     ACTION  Mean Top-5 Recall: 0.31714676977534617\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.17647058823529413  Top5: 0.5882352941176471\n",
      "    @ 0.50s  Top1: 0.16216216216216217  Top5: 0.6486486486486487\n",
      "    @ 0.75s  Top1: 0.22727272727272727  Top5: 0.6818181818181818\n",
      "    @ 1.00s  Top1: 0.25  Top5: 0.7083333333333334\n",
      "    @ 1.25s  Top1: 0.2708333333333333  Top5: 0.7083333333333334\n",
      "    @ 1.50s  Top1: 0.2909090909090909  Top5: 0.7818181818181819\n",
      "    @ 1.75s  Top1: 0.3508771929824561  Top5: 0.7719298245614035\n",
      "    @ 2.00s  Top1: 0.3275862068965517  Top5: 0.7413793103448276\n",
      "    overall_top1: 0.2677165354330709, overall_top5: 0.7139107611548556\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.38235294117647056  Top5: 0.5882352941176471\n",
      "    @ 0.50s  Top1: 0.35135135135135137  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.3409090909090909  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.25  Top5: 0.4583333333333333\n",
      "    @ 1.50s  Top1: 0.2909090909090909  Top5: 0.509090909090909\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.5087719298245614\n",
      "    @ 2.00s  Top1: 0.27586206896551724  Top5: 0.46551724137931033\n",
      "    overall_top1: 0.30183727034120733, overall_top5: 0.49343832020997375\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.38235294117647056\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.32432432432432434\n",
      "    @ 0.75s  Top1: 0.18181818181818182  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.16666666666666666  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.16666666666666666  Top5: 0.2916666666666667\n",
      "    @ 1.50s  Top1: 0.23636363636363636  Top5: 0.32727272727272727\n",
      "    @ 1.75s  Top1: 0.22807017543859648  Top5: 0.3157894736842105\n",
      "    @ 2.00s  Top1: 0.2413793103448276  Top5: 0.3275862068965517\n",
      "    overall_top1: 0.2047244094488189, overall_top5: 0.31496062992125984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584f05fe29f640ab80108c8aa7ef2b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 Train:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9549332d1f4494093c2a6d707a2c14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20 Val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 | Time 11.4s\n",
      "  Train Loss: 0.5014 | Val Loss: 7.8269\n",
      "  VERB   Train Top1: 0.9695024077046549, Top5: 1.0; Val Top1: 0.26246719160104987, Top5: 0.6902887139107612\n",
      "  NOUN   Train Top1: 0.9775280898876404, Top5: 1.0; Val Top1: 0.2887139107611549, Top5: 0.48556430446194226\n",
      "  ACTION Train Top1: 0.9823434991974318, Top5: 1.0; Val Top1: 0.2073490813648294, Top5: 0.3123359580052493\n",
      "  VERB   Val Precision: 0.2274, Recall: 0.1909, F1: 0.1893\n",
      "  NOUN   Val Precision: 0.2563, Recall: 0.1915, F1: 0.2025\n",
      "  ACTION Val Precision: 0.1225, Recall: 0.1418, F1: 0.1258\n",
      "  ---- Mean Top-5 Recall (validation) ----\n",
      "     VERB    Mean Top-5 Recall: 0.6761850131221996\n",
      "     NOUN    Mean Top-5 Recall: 0.4898268545424118\n",
      "     ACTION  Mean Top-5 Recall: 0.3145426031086795\n",
      "  VERB   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.5588235294117647\n",
      "    @ 0.50s  Top1: 0.21621621621621623  Top5: 0.5945945945945946\n",
      "    @ 0.75s  Top1: 0.22727272727272727  Top5: 0.6363636363636364\n",
      "    @ 1.00s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.25s  Top1: 0.22916666666666666  Top5: 0.6458333333333334\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.7454545454545455\n",
      "    @ 1.75s  Top1: 0.3157894736842105  Top5: 0.7894736842105263\n",
      "    @ 2.00s  Top1: 0.3448275862068966  Top5: 0.7931034482758621\n",
      "    overall_top1: 0.26246719160104987, overall_top5: 0.6902887139107612\n",
      "  NOUN   per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.35294117647058826  Top5: 0.5882352941176471\n",
      "    @ 0.50s  Top1: 0.32432432432432434  Top5: 0.5135135135135135\n",
      "    @ 0.75s  Top1: 0.3181818181818182  Top5: 0.4772727272727273\n",
      "    @ 1.00s  Top1: 0.2916666666666667  Top5: 0.4583333333333333\n",
      "    @ 1.25s  Top1: 0.25  Top5: 0.4166666666666667\n",
      "    @ 1.50s  Top1: 0.2727272727272727  Top5: 0.4909090909090909\n",
      "    @ 1.75s  Top1: 0.2807017543859649  Top5: 0.47368421052631576\n",
      "    @ 2.00s  Top1: 0.25862068965517243  Top5: 0.5\n",
      "    overall_top1: 0.2887139107611549, overall_top5: 0.48556430446194226\n",
      "  ACTION per-horizon (time-based):\n",
      "    @ 0.25s  Top1: 0.20588235294117646  Top5: 0.38235294117647056\n",
      "    @ 0.50s  Top1: 0.1891891891891892  Top5: 0.32432432432432434\n",
      "    @ 0.75s  Top1: 0.18181818181818182  Top5: 0.3181818181818182\n",
      "    @ 1.00s  Top1: 0.16666666666666666  Top5: 0.25\n",
      "    @ 1.25s  Top1: 0.20833333333333334  Top5: 0.2708333333333333\n",
      "    @ 1.50s  Top1: 0.23636363636363636  Top5: 0.32727272727272727\n",
      "    @ 1.75s  Top1: 0.22807017543859648  Top5: 0.3157894736842105\n",
      "    @ 2.00s  Top1: 0.22413793103448276  Top5: 0.3275862068965517\n",
      "    overall_top1: 0.2073490813648294, overall_top5: 0.3123359580052493\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "FUSED_CSV_PATH = str(OUTPUT_FUSED_CSV) \n",
    "LABEL_CSV_PATH = str(LABEL_CSV)\n",
    "\n",
    "# load fused and labels\n",
    "fused_df = load_fused_csv_by_path(FUSED_CSV_PATH)\n",
    "labels_df = load_label_csv_by_path(LABEL_CSV_PATH)\n",
    "\n",
    "# Training & dataset\n",
    "T_OBS = 90\n",
    "FPS = 30.0\n",
    "HORIZONS_S = [0.25, 0.5, 0.75, 1.0, 1.25, 1.50, 1.75, 2.0]\n",
    "K_FUT = len(HORIZONS_S)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 20\n",
    "LR = 1e-4\n",
    "WD = 1e-4\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# dataset\n",
    "dataset = SingleVideoAnticipationDataset(\n",
    "    fused_df,\n",
    "    labels_df,\n",
    "    t_obs=T_OBS,\n",
    "    k_fut=K_FUT,\n",
    "    feat_dim=FEAT_DIM,\n",
    "    fps=FPS,\n",
    "    horizons_s=HORIZONS_S\n",
    ")\n",
    "\n",
    "\n",
    "# split (60/40)\n",
    "indices = list(range(len(dataset)))\n",
    "random.seed(SEED)\n",
    "random.shuffle(indices)\n",
    "split_at = int(0.6 * len(indices))\n",
    "train_idx = indices[:split_at]; val_idx = indices[split_at:]\n",
    "train_ds = Subset(dataset, train_idx); val_ds = Subset(dataset, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=(DEVICE==\"cuda\"))\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=(DEVICE==\"cuda\"))\n",
    "\n",
    "# detect num classes\n",
    "def detect_num_classes_from_labels_df(labels_df):\n",
    "    verbs = set(); nouns = set(); actions = set()\n",
    "    for cand in [\"Verb_class\",\"verb\",\"Verb\",\"verb_class\"]:\n",
    "        if cand in labels_df.columns:\n",
    "            verbs.update(labels_df[cand].dropna().astype(int).tolist()); break\n",
    "    for cand in [\"Noun_class\",\"noun\",\"Noun\",\"noun_class\"]:\n",
    "        if cand in labels_df.columns:\n",
    "            nouns.update(labels_df[cand].dropna().astype(int).tolist()); break\n",
    "    for cand in [\"Action_class\",\"action\",\"Action\",\"ActionLabel\"]:\n",
    "        if cand in labels_df.columns:\n",
    "            actions.update(labels_df[cand].dropna().astype(int).tolist()); break\n",
    "    nv = (max(verbs) + 1) if len(verbs) > 0 else 1\n",
    "    nn_ = (max(nouns) + 1) if len(nouns) > 0 else 1\n",
    "    na = (max(actions) + 1) if len(actions) > 0 else 1\n",
    "    return {\"verb\": int(nv), \"noun\": int(nn_), \"action\": int(na)}\n",
    "\n",
    "num_classes = detect_num_classes_from_labels_df(labels_df)\n",
    "print(\"Detected num_classes:\", num_classes)\n",
    "\n",
    "# instantiate model, optimizer, scheduler\n",
    "model = AnticipationModel(feat_dim=FEAT_DIM, num_classes=num_classes, k_fut=K_FUT).to(DEVICE)\n",
    "opt = optim.Adam(model.parameters(), lr=LR, weight_decay=WD)\n",
    "sched = optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "# instantiate auxiliary helpers and weights (used by LOSS_MODE)\n",
    "focal_fn = FocalLoss(gamma=2.0, ignore_index=IGNORE_INDEX)\n",
    "focal_alpha = 0.3\n",
    "smooth_weight = 0.1\n",
    "contrast_weight = 0.1\n",
    "contrast_temperature = 0.07\n",
    "graph_rec_weight = 0.05\n",
    "\n",
    "# training loop\n",
    "best_val_loss = float(\"inf\")\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "    model.train()\n",
    "    train_loss_sum = 0.0; train_samples = 0\n",
    "    train_counts = {\"verb_top1\":[0,0],\"verb_top5\":[0,0],\"noun_top1\":[0,0],\"noun_top5\":[0,0],\"action_top1\":[0,0],\"action_top5\":[0,0]}\n",
    "\n",
    "    for F_batch, y_multi, meta in tqdm(train_loader, desc=f\"Epoch {epoch} Train\"):\n",
    "        F_batch = F_batch.to(DEVICE)\n",
    "        y_v = y_multi[\"verb\"].to(DEVICE)\n",
    "        y_n = y_multi[\"noun\"].to(DEVICE)\n",
    "        y_a = y_multi[\"action\"].to(DEVICE)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits, dec_outs, gat_out = model(F_batch)\n",
    "\n",
    "        # base CE\n",
    "        loss_v_ce = masked_cross_entropy(logits[\"verb\"], y_v)\n",
    "        loss_n_ce = masked_cross_entropy(logits[\"noun\"], y_n)\n",
    "        loss_a_ce = masked_cross_entropy(logits[\"action\"], y_a)\n",
    "        base_loss = loss_a_ce + 0.5 * loss_v_ce + 0.5 * loss_n_ce\n",
    "\n",
    "        # init aux terms\n",
    "        focal_term = torch.tensor(0.0, device=F_batch.device)\n",
    "        smooth_term = torch.tensor(0.0, device=F_batch.device)\n",
    "        contrast_term = torch.tensor(0.0, device=F_batch.device)\n",
    "        graph_term = torch.tensor(0.0, device=F_batch.device)\n",
    "\n",
    "        # LOSS_MODE branches\n",
    "        if LOSS_MODE == \"ce\":\n",
    "            loss = base_loss\n",
    "\n",
    "        elif LOSS_MODE == \"focal\":\n",
    "            f_v = focal_fn(logits[\"verb\"], y_v)\n",
    "            f_n = focal_fn(logits[\"noun\"], y_n)\n",
    "            f_a = focal_fn(logits[\"action\"], y_a)\n",
    "            loss_v = (1.0 - focal_alpha) * loss_v_ce + focal_alpha * f_v\n",
    "            loss_n = (1.0 - focal_alpha) * loss_n_ce + focal_alpha * f_n\n",
    "            loss_a = (1.0 - focal_alpha) * loss_a_ce + focal_alpha * f_a\n",
    "            focal_term = (f_v + f_n + f_a) / 3.0\n",
    "            loss = loss_a + 0.5 * loss_v + 0.5 * loss_n\n",
    "\n",
    "        elif LOSS_MODE == \"smooth\":\n",
    "            loss = base_loss\n",
    "            if dec_outs is not None:\n",
    "                smooth_term = temporal_smoothness_loss(dec_outs)\n",
    "                loss = loss + smooth_weight * smooth_term\n",
    "\n",
    "        elif LOSS_MODE == \"contrast\":\n",
    "            loss = base_loss\n",
    "            feats_for_contrast = F.normalize(F_batch[:, -1, :], dim=1)\n",
    "            labels_for_contrast = y_a[:, 0].clone().detach()\n",
    "            valid_mask = (labels_for_contrast != IGNORE_INDEX)\n",
    "            if int(valid_mask.sum().item()) > 1:\n",
    "                contrast_term = supervised_contrastive_loss(feats_for_contrast[valid_mask], labels_for_contrast[valid_mask], temperature=contrast_temperature)\n",
    "                loss = loss + contrast_weight * contrast_term\n",
    "\n",
    "        elif LOSS_MODE == \"graph\":\n",
    "            loss = base_loss\n",
    "            if gat_out is not None:\n",
    "                graph_term = graph_reconstruction_loss(gat_out, F_batch.detach(), k=K)\n",
    "                loss = loss + graph_rec_weight * graph_term\n",
    "\n",
    "        elif LOSS_MODE == \"combined\":\n",
    "            f_v = focal_fn(logits[\"verb\"], y_v)\n",
    "            f_n = focal_fn(logits[\"noun\"], y_n)\n",
    "            f_a = focal_fn(logits[\"action\"], y_a)\n",
    "            loss_v = (1.0 - focal_alpha) * loss_v_ce + focal_alpha * f_v\n",
    "            loss_n = (1.0 - focal_alpha) * loss_n_ce + focal_alpha * f_n\n",
    "            loss_a = (1.0 - focal_alpha) * loss_a_ce + focal_alpha * f_a\n",
    "            focal_term = (f_v + f_n + f_a) / 3.0\n",
    "            if dec_outs is not None:\n",
    "                smooth_term = temporal_smoothness_loss(dec_outs)\n",
    "            feats_for_contrast = F.normalize(F_batch[:, -1, :], dim=1)\n",
    "            labels_for_contrast = y_a[:, 0].clone().detach()\n",
    "            if int((labels_for_contrast != IGNORE_INDEX).sum().item()) > 1:\n",
    "                contrast_term = supervised_contrastive_loss(feats_for_contrast[labels_for_contrast != IGNORE_INDEX], labels_for_contrast[labels_for_contrast != IGNORE_INDEX], temperature=contrast_temperature)\n",
    "            if gat_out is not None:\n",
    "                graph_term = graph_reconstruction_loss(gat_out, F_batch.detach(), k=K)\n",
    "            loss = loss_a + 0.5 * loss_v + 0.5 * loss_n\n",
    "            loss = loss + smooth_weight * smooth_term + contrast_weight * contrast_term + graph_rec_weight * graph_term\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown LOSS_MODE: {LOSS_MODE}\")\n",
    "\n",
    "        # backward + step\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # bookkeeping\n",
    "        b = F_batch.size(0)\n",
    "        train_loss_sum += float(loss.item()) * b\n",
    "        train_samples += b\n",
    "\n",
    "        for (task, lab, lg) in [(\"verb\", y_v, logits[\"verb\"]), (\"noun\", y_n, logits[\"noun\"]), (\"action\", y_a, logits[\"action\"])]:\n",
    "            h1, t1 = topk_counts(lg.detach().cpu(), lab.detach().cpu(), k=1)\n",
    "            h5, t5 = topk_counts(lg.detach().cpu(), lab.detach().cpu(), k=5)\n",
    "            train_counts[f\"{task}_top1\"][0] += h1; train_counts[f\"{task}_top1\"][1] += t1\n",
    "            train_counts[f\"{task}_top5\"][0] += h5; train_counts[f\"{task}_top5\"][1] += t5\n",
    "\n",
    "    # train metrics\n",
    "    train_loss = train_loss_sum / max(1, train_samples)\n",
    "    train_metrics = {}\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        h1,t1 = train_counts[f\"{task}_top1\"]; h5,t5 = train_counts[f\"{task}_top5\"]\n",
    "        train_metrics[f\"{task}_top1\"] = (h1 / t1) if t1>0 else None\n",
    "        train_metrics[f\"{task}_top5\"] = (h5 / t5) if t5>0 else None\n",
    "\n",
    "    # ------------- VALIDATION -------------\n",
    "    model.eval()\n",
    "    val_loss_sum = 0.0; val_samples = 0\n",
    "    val_counts = {\"verb_top1\":[0,0],\"verb_top5\":[0,0],\"noun_top1\":[0,0],\"noun_top5\":[0,0],\"action_top1\":[0,0],\"action_top5\":[0,0]}\n",
    "    val_logits_store = {\"verb\": [], \"noun\": [], \"action\": []}\n",
    "    val_labels_store = {\"verb\": [], \"noun\": [], \"action\": []}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for F_batch, y_multi, meta in tqdm(val_loader, desc=f\"Epoch {epoch} Val\"):\n",
    "            F_batch = F_batch.to(DEVICE)\n",
    "            y_v = y_multi[\"verb\"].to(DEVICE)\n",
    "            y_n = y_multi[\"noun\"].to(DEVICE)\n",
    "            y_a = y_multi[\"action\"].to(DEVICE)\n",
    "\n",
    "            logits, _, _ = model(F_batch)\n",
    "            loss_v = masked_cross_entropy(logits[\"verb\"], y_v)\n",
    "            loss_n = masked_cross_entropy(logits[\"noun\"], y_n)\n",
    "            loss_a = masked_cross_entropy(logits[\"action\"], y_a)\n",
    "            loss = loss_a + 0.5 * loss_v + 0.5 * loss_n\n",
    "\n",
    "            b = F_batch.size(0)\n",
    "            val_loss_sum += float(loss.item()) * b\n",
    "            val_samples += b\n",
    "\n",
    "            for (task, lab, lg) in [(\"verb\", y_v, logits[\"verb\"]), (\"noun\", y_n, logits[\"noun\"]), (\"action\", y_a, logits[\"action\"])]:\n",
    "                h1,t1 = topk_counts(lg.detach().cpu(), lab.detach().cpu(), k=1)\n",
    "                h5,t5 = topk_counts(lg.detach().cpu(), lab.detach().cpu(), k=5)\n",
    "                val_counts[f\"{task}_top1\"][0] += h1; val_counts[f\"{task}_top1\"][1] += t1\n",
    "                val_counts[f\"{task}_top5\"][0] += h5; val_counts[f\"{task}_top5\"][1] += t5\n",
    "\n",
    "            val_logits_store[\"verb\"].append(logits[\"verb\"].detach().cpu())\n",
    "            val_logits_store[\"noun\"].append(logits[\"noun\"].detach().cpu())\n",
    "            val_logits_store[\"action\"].append(logits[\"action\"].detach().cpu())\n",
    "            val_labels_store[\"verb\"].append(y_v.detach().cpu())\n",
    "            val_labels_store[\"noun\"].append(y_n.detach().cpu())\n",
    "            val_labels_store[\"action\"].append(y_a.detach().cpu())\n",
    "\n",
    "    val_loss = val_loss_sum / max(1, val_samples)\n",
    "\n",
    "    # overall val metrics\n",
    "    val_metrics = {}\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        h1,t1 = val_counts[f\"{task}_top1\"]; h5,t5 = val_counts[f\"{task}_top5\"]\n",
    "        val_metrics[f\"{task}_top1\"] = (h1 / t1) if t1>0 else None\n",
    "        val_metrics[f\"{task}_top5\"] = (h5 / t5) if t5>0 else None\n",
    "\n",
    "    # per-horizon metrics\n",
    "    per_horizon_metrics = {\"verb\":{},\"noun\":{},\"action\":{}}\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        if len(val_logits_store[task]) == 0:\n",
    "            continue\n",
    "        logits_all = torch.cat(val_logits_store[task], dim=0)\n",
    "        labels_all = torch.cat(val_labels_store[task], dim=0)\n",
    "        m = topk_accuracy_per_task(logits_all, labels_all, topk=(1,5), ignore_index=IGNORE_INDEX)\n",
    "        per_horizon_metrics[task] = m\n",
    "\n",
    "    # PRF macro\n",
    "    prf_metrics = {\"verb\":{}, \"noun\":{}, \"action\":{}}\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        if len(val_logits_store[task]) == 0:\n",
    "            continue\n",
    "        logits_all = torch.cat(val_logits_store[task], dim=0)\n",
    "        labels_all = torch.cat(val_labels_store[task], dim=0)\n",
    "        preds_all = logits_all.argmax(dim=-1)\n",
    "        mask = (labels_all != IGNORE_INDEX)\n",
    "        if mask.sum().item() == 0:\n",
    "            continue\n",
    "        y_true = labels_all[mask].numpy()\n",
    "        y_pred = preds_all[mask].numpy()\n",
    "        p,r,f1,_ = precision_recall_fscore_support(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "        prf_metrics[task][\"precision\"] = p; prf_metrics[task][\"recall\"] = r; prf_metrics[task][\"f1\"] = f1\n",
    "\n",
    "    # mean top-5 recall\n",
    "    mean_top5_recall = {}\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        mh = per_horizon_metrics[task]\n",
    "        if not mh:\n",
    "            mean_top5_recall[task] = None; continue\n",
    "        vals = []\n",
    "        for h_idx in range(K_FUT):\n",
    "            key = f\"per_h{h_idx+1}_top5\"\n",
    "            if key in mh and mh[key] is not None:\n",
    "                vals.append(mh[key])\n",
    "        mean_top5_recall[task] = float(np.mean(vals)) if len(vals) > 0 else None\n",
    "\n",
    "    sched.step(val_loss)\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    # print summary\n",
    "    print(f\"Epoch {epoch}/{NUM_EPOCHS} | Time {elapsed:.1f}s\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        print(f\"  {task.upper():6s} Train Top1: {train_metrics[f'{task}_top1']}, Top5: {train_metrics[f'{task}_top5']}; Val Top1: {val_metrics[f'{task}_top1']}, Top5: {val_metrics[f'{task}_top5']}\")\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        if prf_metrics[task]:\n",
    "            print(f\"  {task.upper():6s} Val Precision: {prf_metrics[task]['precision']:.4f}, Recall: {prf_metrics[task]['recall']:.4f}, F1: {prf_metrics[task]['f1']:.4f}\")\n",
    "    print(\"  ---- Mean Top-5 Recall (validation) ----\")\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        print(f\"     {task.upper():6s}  Mean Top-5 Recall: {mean_top5_recall[task]}\")\n",
    "    # per-horizon\n",
    "    for task in [\"verb\",\"noun\",\"action\"]:\n",
    "        mh = per_horizon_metrics[task]\n",
    "        if not mh:\n",
    "            continue\n",
    "        print(f\"  {task.upper():6s} per-horizon (time-based):\")\n",
    "        for h_idx, t_sec in enumerate(HORIZONS_S):\n",
    "            key1 = f\"per_h{h_idx+1}_top1\"; key5 = f\"per_h{h_idx+1}_top5\"\n",
    "            v1 = mh.get(key1, None); v5 = mh.get(key5, None)\n",
    "            print(f\"    @ {t_sec:4.2f}s  Top1: {v1}  Top5: {v5}\")\n",
    "        print(f\"    overall_top1: {mh.get('overall_top1', None)}, overall_top5: {mh.get('overall_top5', None)}\")\n",
    "\n",
    "    # save best\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({'epoch': epoch, 'model_state': model.state_dict(), 'opt_state': opt.state_dict(), 'val_loss': val_loss}, BEST_MODEL_PATH)\n",
    "        print(f\"[SAVED BEST] -> {BEST_MODEL_PATH}\")\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
